{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark RDD Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khởi tạo SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tạo một RDD từ một collection\n",
    "### 1.1 Tạo một Python list gồm các số từ 1 đến 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb = range(1,101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Tạo một RDD từ Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbRDD = sc.parallelize(numb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. In ra kiểu của `numbRDD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of RDD is <class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The type of RDD is\", type(numbRDD))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tạo một RDD từ một external dataset\n",
    "### 2.1. Tạo một RDD từ một file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './README.md' # File readme của thư mục cài đặt Spark\n",
    "fileRDD = sc.textFile(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Kiểm tra kiểu của `fileRDD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file type of fileRDD is <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The file type of fileRDD is\", type(fileRDD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Phân hoạch dữ liệu\n",
    "### 3.1. Kiểm tra số partition của `fileRDD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions in fileRDD is 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of partitions in fileRDD is\", fileRDD.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Tạo `fileRDD_part` từ `file_path` với 5 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileRDD_part = sc.textFile(file_path, minPartitions=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Kiểm tra số partition của `fileRDD_part`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of partitions in fileRDD_part is 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of partitions in fileRDD_part is\", fileRDD_part.getNumPartitions())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Map and Collect\n",
    "### 4.1. Tạo một map() transformation để tính lũy thừa bậc 3 của các phần tử trong `numbRDD`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubedRDD = numbRDD.map(lambda x: x ** 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Collect kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_all = cubedRDD.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. In ra các phần tử từ `numbers_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "27\n",
      "64\n",
      "125\n",
      "216\n",
      "343\n",
      "512\n",
      "729\n",
      "1000\n",
      "1331\n",
      "1728\n",
      "2197\n",
      "2744\n",
      "3375\n",
      "4096\n",
      "4913\n",
      "5832\n",
      "6859\n",
      "8000\n",
      "9261\n",
      "10648\n",
      "12167\n",
      "13824\n",
      "15625\n",
      "17576\n",
      "19683\n",
      "21952\n",
      "24389\n",
      "27000\n",
      "29791\n",
      "32768\n",
      "35937\n",
      "39304\n",
      "42875\n",
      "46656\n",
      "50653\n",
      "54872\n",
      "59319\n",
      "64000\n",
      "68921\n",
      "74088\n",
      "79507\n",
      "85184\n",
      "91125\n",
      "97336\n",
      "103823\n",
      "110592\n",
      "117649\n",
      "125000\n",
      "132651\n",
      "140608\n",
      "148877\n",
      "157464\n",
      "166375\n",
      "175616\n",
      "185193\n",
      "195112\n",
      "205379\n",
      "216000\n",
      "226981\n",
      "238328\n",
      "250047\n",
      "262144\n",
      "274625\n",
      "287496\n",
      "300763\n",
      "314432\n",
      "328509\n",
      "343000\n",
      "357911\n",
      "373248\n",
      "389017\n",
      "405224\n",
      "421875\n",
      "438976\n",
      "456533\n",
      "474552\n",
      "493039\n",
      "512000\n",
      "531441\n",
      "551368\n",
      "571787\n",
      "592704\n",
      "614125\n",
      "636056\n",
      "658503\n",
      "681472\n",
      "704969\n",
      "729000\n",
      "753571\n",
      "778688\n",
      "804357\n",
      "830584\n",
      "857375\n",
      "884736\n",
      "912673\n",
      "941192\n",
      "970299\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "for numb in numbers_all:\n",
    "    print(numb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filter and Count\n",
    "### 5.1 Áp dụng filter trên `fileRDD` để chọn ra những dòng có từ `Spark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileRDD_filter = fileRDD.filter(lambda line: 'Spark' in line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Cho biết có bao nhiêu dòng từ `fileRDD`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of lines with the keyword Spark is 20\n"
     ]
    }
   ],
   "source": [
    "print(\"The total number of lines with the keyword Spark is\", fileRDD_filter.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. In 5 dòng đầu của `fileRDD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Apache Spark\n",
      "Spark is a unified analytics engine for large-scale data processing. It provides\n",
      "rich set of higher-level tools including Spark SQL for SQL and DataFrames,\n",
      "pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing,\n",
      "[![PySpark Coverage](https://codecov.io/gh/apache/spark/branch/master/graph/badge.svg)](https://codecov.io/gh/apache/spark)\n"
     ]
    }
   ],
   "source": [
    "for line in fileRDD_filter.take(5):\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ReduceBykey and Collect  \n",
    "### 6.1. Tạo một `PairRDD` tên `Rdd` như sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdd = sc.parallelize([(1,2),(3,4),(3,6),(4,5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Áp dụng `reduceByKey()` operation trên Rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdd_Reduced = Rdd.reduceByKey(lambda x, y: x + y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Duyệt và in ra kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 1 has 2 Counts\n",
      "Key 3 has 10 Counts\n",
      "Key 4 has 5 Counts\n"
     ]
    }
   ],
   "source": [
    "for num in Rdd_Reduced.collect():\n",
    "    print(\"Key {} has {} Counts\".format(num[0], num[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SortByKey and Collect\n",
    "### 7.1. Sắp xếp `Rdd_Reduced` theo khóa giảm dần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rdd_Reduced_Sort = Rdd_Reduced.sortByKey(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Duyệt và in ra kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 4 has 5 Counts\n",
      "Key 3 has 10 Counts\n",
      "Key 1 has 2 Counts\n"
     ]
    }
   ],
   "source": [
    "for num in Rdd_Reduced_Sort.collect():\n",
    "    print(\"Key {} has {} Counts\".format(num[0], num[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. CountingBykeys\n",
    "### 8.1. Đếm số key khác nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = Rdd.keys().distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Kiểm tra kiểu của biến `total`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of total is <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"The type of total is\", type(total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Duyệt và in ra kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key 1 has 2 counts\n",
      "key 3 has 10 counts\n",
      "key 4 has 5 counts\n"
     ]
    }
   ],
   "source": [
    "for k, v in Rdd_Reduced.collect():\n",
    "    print(\"key\", k, \"has\", v, \"counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tạo biến `baseRDD` từ file và thực hiện các transform\n",
    "### 9.1 Tạo biến `baseRDD` từ `file_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './README.md'\n",
    "baseRDD = sc.textFile(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2. Biến đổi các dòng trong `baseRDD` thành các từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitRDD = baseRDD.flatMap(lambda x: x.split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3. Đếm tổng số từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in splitRDD: 516\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of words in splitRDD:\", splitRDD.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Loại bỏ stop word và áp dụng reduce opperator trên tập dữ liệu\n",
    "### 10.1. Chuyển các từ sang dạng chữ thường (lower case) và loại bỏ các stop words từ biến `stop_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['a', 'an', 'the', 'is', 'be', 'was', 'were', 'it', 'this', 'that', 'but', 'if', 'or', 'not']\n",
    "splitRDD_no_stop = splitRDD.filter(lambda x: x.lower() not in stop_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2. Tạo các tuple có dạng (word, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitRDD_no_stop_words = splitRDD_no_stop.map(lambda w: (w, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3. Đếm tần số của mỗi từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultRDD = splitRDD_no_stop_words.reduceByKey(lambda x, y: x + y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. In tần số của mỗi từ\n",
    "### 11.1. Hiển thị 10 từ đầu và tần số của nó trong `resultRDD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('#', 1)\n",
      "('Apache', 1)\n",
      "('Spark', 15)\n",
      "('unified', 1)\n",
      "('analytics', 1)\n",
      "('engine', 2)\n",
      "('provides', 1)\n",
      "('high-level', 1)\n",
      "('APIs', 1)\n",
      "('in', 5)\n"
     ]
    }
   ],
   "source": [
    "for word in resultRDD.take(10):\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Hoán đổi giữa key và value trong `resultRDD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultRDD_swap = resultRDD.map(lambda x: (x[1], x[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3. Sắp xếp các key theo thứ tự giảm dần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultRDD_swap_sort = resultRDD_swap.sortByKey(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4. Hiển thị 10 từ xuất hiện nhiều nhất trong `resultRDD_swap_sort`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16, to\n",
      "15, Spark\n",
      "13, for\n",
      "9, and\n",
      "9, ##\n",
      "8, on\n",
      "8, ```\n",
      "7, run\n",
      "6, can\n",
      "6, ```bash\n"
     ]
    }
   ],
   "source": [
    "for word in resultRDD_swap_sort.take(10):\n",
    "    print(\"{}, {}\".format(word[0], word[1]))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
